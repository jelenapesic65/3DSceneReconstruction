{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CaOnXnkx9wk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthEstimator:\n",
        "    def __init__(self, model_type=\"DPT_Large\"):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.transform = Compose([\n",
        "            ToTensor(),\n",
        "            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def estimate_depth(self, rgb_frame):\n",
        "        img = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2RGB)\n",
        "        input_batch = self.transform(img).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = self.model(input_batch)\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=img.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "        return prediction.cpu().numpy()\n",
        "\n",
        "    def normalize_depth(self, depth_map):\n",
        "        return cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "\n",
        "def process_video_frames(input_video_path, output_dir):\n",
        "    os.makedirs(os.path.join(output_dir, \"rgb\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"depth_raw\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"depth_vis\"), exist_ok=True)\n",
        "\n",
        "    depth_estimator = DepthEstimator()\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    skip = 7\n",
        "    frame_idx = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % skip == 0:\n",
        "\n",
        "          depth_map = depth_estimator.estimate_depth(frame)\n",
        "          depth_vis = depth_estimator.normalize_depth(depth_map)\n",
        "\n",
        "          frame_name = int((frame_idx) / skip)\n",
        "          print(frame_name)\n",
        "          # ---- save files ----\n",
        "          rgb_path   = os.path.join(output_dir, \"rgb\",   f\"frame_{frame_name:02d}.png\")\n",
        "          depth_raw  = os.path.join(output_dir, \"depth_raw\", f\"depth_{frame_name:02d}.npy\")\n",
        "          depth_img  = os.path.join(output_dir, \"depth_vis\", f\"depth_{frame_name:02d}.png\")\n",
        "\n",
        "          ok = cv2.imwrite(rgb_path, frame)            # save RGB frame\n",
        "          print (\"The picture status is:\", ok)\n",
        "          np.save(depth_raw, depth_map)           # full-precision depth\n",
        "          cv2.imwrite(depth_img, depth_vis)       # 8-bit visualization\n",
        "\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "mEi_NLLGyFlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/3DGS/\n",
        "input_video_path = \"/content/drive/MyDrive/3DGS/nagoya.mp4\"      # folder with your images\n",
        "output_dir = \"/content/drive/MyDrive/3DGS/results\"   # where results will be saved\n",
        "\n",
        "import os\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "process_video_frames(input_video_path, output_dir)\n"
      ],
      "metadata": {
        "id": "UfKbMdhHyHVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZe0AIgUy_gq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}